------------------Session 1: Some useful commands------------------
docker build -t projectFolder/lobsters:2.1.0 lobsters
docker images
kubectl create -f deployments/lobsters.yaml

kubectl get secrets
  kubectl describe secrets/<name of any secret from above command>
kubectl describe svc <name of service: e.g lobsters> 
kubectl logs <container's name from "kubectl get pods"> -f
  -f : follow the log
------------------Session 2: Deploy a demo-------------------------
(1) get the application to deploy
- make sure nothing running:
  $ kubectl get pods
- we need mysql, so we need a deployment to deploy mysql

(2) run this command to create the deployment for the above mysql
- $ kubectl create -f deployment/mysql.yaml
- we check the result by below command
  $ kubectl get pods
- at this time, "mysql" container is being created

(3) we have to create a service for this, so that other application can find it
- $ kubectl create -f service/mysql.yaml
- we can check by :
  $ kubectl get svc

(4) The next thing we need is our web app
- Let's deploy the application
- $ kubectl create -f deployment/lobsters.yaml
- Check again by: $ kubectl get pods
- We will get an IP address, check by: $ kubectl get svc

(5) create the database migration
- we need to run a job one time 
- we need to follow the same flow, no need to go to server, no jumb box
- we give a workflow to the scheduler: run one rake task, once, until it's successful, then kill it
  + similar to a web-app but we just run 1 command, then exit
- $ kubectl create -f jobs/lobsters-db-schema-load.yaml
- we can review by: $ watch kubectl get jobs

(6) create the database seed data
- $ kubectl create -f jobs/lobsters-db-seed.yaml

(7) scale the app
- e.g: change replica number from 1 to 10, then execute command
- $ kubectl apply -f  deployment/lobsters.yaml

(8) If we have newly updated image for the app, use below command to tell k8s to have new image
- Edit file deployment/lobsters.yaml with new image's name
- $ kubectl apply -f deployment/lobsters.yaml
- Cluster's job will do a rolling update based on policy (???)

(9) Create a k8s extension, to have support for https 
- $ kubectl create -f extensions/certificate.yaml

(10) Here is that we need
- K8s will automatically create a restin point 
  + store it inside this backend and manage everything to do with this particular state  
- with this object, we will create a new tool
  + watch for those changes 
  + & do some implementation that when I see this certificate object, then it can go 
    + and interact with list of encrypting and give me a real certificate back 
  + and we want this to happen behind the scene so, when it's done we want it to populate the secret 

(10.1) Here is what we do:
- We add nginx above the existing pods (refer to file deployments/lobsters-secure.yaml)
  + we don't have to work with dev team
- We put a container on TOP of the same pod
  + That container gonna takes in the HTTPS traffic 
  + That container needs a configuration, because it needs to know how to proxy to a backend
  + Then it needs some certificate, and nginx happens to want to load this certificate from file system
    * So, environment variable won't work here 
- Summary: so we add a container right inside a pod, and then refer to 2 secrets
  + One secret is gonna be the TLS certificate and I want that to come from the encrypt 
    * But I'm not gonna tell my app about this encrypt, I'm not gonna tell my system about this encrypt
    * I wanna hold these abstraction
- So, the next thing I want to do now is to create this config file for nginx
- $ kubectl create configmap nginx --from-file configs/lobsters.conf
  + It will upload as the name on the disk
  + Through pushing this, it actually generates a object in k8s so now that will be the desired state
- Check again by: $ kubectl get configmaps
  + That holding our configuration file and inside of that the configmap with the samename with the thing that was on disk

(10.2) The next thing we want to do is to create the secret
  - I want it to be automated, I don't want to go and provision certificate: file kube-cert-manager.yaml
  
(10.3) We wanna start the controller 
- What we are trying to do is to get a valid certificate from the encrypt that my browser trust		
	and inject it as the k8s secret on the backend	
	so that my pod doesn't know the difference		
- In the background, we do not do any compilation		
	so we don't create provider and then recompile something	
- The deamon run in the background and they watching for changes as soon as that certificate object created it's gonna		
	kickoff the job get the certificate from that encrypt , bring back to resolve and inject that into secret in realtime , 
  no delays here
- $ kubectl create -f deployment/kube-cert-manager.yaml
	
